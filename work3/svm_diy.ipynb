{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集（无用）\n",
    "def data_split(data, test_size):\n",
    "    trn_data = {}\n",
    "    val_data = {}\n",
    "\n",
    "    for label, data in data.items():\n",
    "        lens = len(data[label])\n",
    "        print(lens)\n",
    "        trn_data[label] = data[: lens * (1 - test_size)]\n",
    "        val_data[label] = data[lens * (1 - test_size) :]\n",
    "    \n",
    "    return trn_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# 读取mat\n",
    "trn_mat = scipy.io.loadmat(\"data/train_data.mat\")\n",
    "trn_data = trn_mat[\"train\"]\n",
    "# print(len(trn_data))\n",
    "x_len = len(trn_data)\n",
    "\n",
    "# 标注数据label\n",
    "trn_label = [i + 1 for i in range(x_len)]\n",
    "# print(trn_label)\n",
    "\n",
    "# 将label与data组合为字典\n",
    "trn_dict = {}\n",
    "for i in range(x_len):\n",
    "    trn_dict[i+1] = trn_data[i]\n",
    "# print(len(trn_dict))\n",
    "print(type(trn_dict[1]))\n",
    "\n",
    "# 读取测试集\n",
    "val_mat = scipy.io.loadmat('data/test_data.mat')\n",
    "val_data = val_mat['test']\n",
    "val_data = val_data\n",
    "print(type(val_data[1]))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义SVM\n",
    "class LinearSVM:\n",
    "    # 定义学习率、正则化强度、迭代次数\n",
    "    def __init__(self, lr=1e-3, reg=1e-5, num_iter=1000):\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.num_iter = num_iter\n",
    "        \n",
    "    # 计算损失和梯度\n",
    "    def compute_loss_and_grad(self, x, y):\n",
    "        num_trn = x.shape[0]\n",
    "        num_cls = np.max(y) # 样本类别的数量，在预处理数据时已+1，此处无需+1\n",
    "        scores = x.dot(self.W)  # 获取全分数矩阵\n",
    "        correct_cls_scores = scores[np.arange(num_trn), y] # 提取正确类别的分数 \n",
    "        \n",
    "        margins = np.maximum(0, scores - correct_cls_scores[:, np.newaxis] + 1) # 计算损失边缘\n",
    "        margins[np.arange(num_trn), y] = 0  # 令正确分类损失为0\n",
    "        loss = np.sum(margins) / num_trn    # 计算损失\n",
    "        loss += 0.5 * self.reg * np.sum(self.W * self.W)    # 对损失进行正则化处理，防止过拟合\n",
    "        \n",
    "        margins[margins>0] = 1  # 将边缘损失矩阵大于零的部分设为1，方便计算梯度\n",
    "        margins[np.arange(num_trn), y] = -np.sum(margins, axis=1)   \n",
    "        dW = x.T.dot(margins) / num_trn # 计算权重矩阵的梯度取平均值，用于更新模型参数\n",
    "        dW += self.reg * self.W # 正则化梯度，用于惩罚过大的权重\n",
    "        \n",
    "        return loss, dW\n",
    "\n",
    "    # 训练\n",
    "    def fit(self, x, y):\n",
    "        num_trn, dim = x.shape\n",
    "        num_cls = np.max(y) + 1\n",
    "        self.W = 0.001 * np.random.randn(dim, num_cls)  # 生成一个初始权重矩阵\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            loss, grad = self.compute_loss_and_grad(x, y)\n",
    "            self.W -= self.lr * grad    # 梯度下降法更新权重\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}/{self.num_iter}, Loss: {loss}\")\n",
    "                \n",
    "    # 预测\n",
    "    def predict(self, x):\n",
    "        scores = x.dot(self.W)  # 利用权重进行预测\n",
    "        if scores.size == 0:\n",
    "            return []  # 如果输入序列为空，则返回空列表\n",
    "        return np.argmax(scores, axis=1)    # 输出得分最高的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 15, 28, 28)\n",
      "Iteration 0/1000, Loss: 266.8600838540189\n",
      "Iteration 100/1000, Loss: 0.36589494565902514\n",
      "Iteration 200/1000, Loss: 0.01214613232435776\n",
      "Iteration 300/1000, Loss: 0.00020144803915678674\n",
      "Iteration 400/1000, Loss: 0.0002014476362611093\n",
      "Iteration 500/1000, Loss: 0.00020144723336623765\n",
      "Iteration 600/1000, Loss: 0.00020144683047217183\n",
      "Iteration 700/1000, Loss: 0.00020144642757891174\n",
      "Iteration 800/1000, Loss: 0.00020144602468645745\n",
      "Iteration 900/1000, Loss: 0.00020144562179480894\n"
     ]
    }
   ],
   "source": [
    "# 收集并转换数据\n",
    "x_trn = []\n",
    "y_trn = []\n",
    "for y, x in trn_dict.items():\n",
    "    x_trn.append(x)\n",
    "    y_trn.append([y] * len(x))\n",
    "\n",
    "x_trn = np.array(x_trn)\n",
    "y_trn = np.array(y_trn)\n",
    "print(x_trn.shape)\n",
    "\n",
    "# 重塑数据\n",
    "x_trn = x_trn.reshape(200 * 15, 28 * 28).astype(np.float64)\n",
    "y_trn = np.repeat(np.arange(200), 15)\n",
    "x_val = val_data.reshape(val_data.shape[0], -1).astype(np.float64)\n",
    "\n",
    "# 计算并减去均值图像\n",
    "mean_img = np.mean(x_trn, axis=0).astype(np.float64)\n",
    "x_trn -= mean_img\n",
    "x_val -= mean_img\n",
    "\n",
    "# 训练 SVM\n",
    "svm = LinearSVM()\n",
    "svm.fit(x_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[  6 172 194  12  71 162 194 134  13  28  91 153 187 147 121  94 116  12\n",
      " 183  21  71 180  39  13 177  91 102   1 199  25  94 155  36 118   5  76\n",
      " 176  18 176 187  57   9  43   3 111  36  79  84 189 141  75 125 163  19\n",
      " 123  85   9 145  56  31  62  24 137 167  81 119 107  97 191 170  36 160\n",
      " 166 116  14 119 182  55 134 137  33 102 147  64   8 163  79 177  90  21\n",
      "  44 119 104  85 101 163 138  71 127   2 155  56 155  71  27 171  45  85\n",
      "   0  16  31   9  30  68 130 130 176   3  40 190 193  70 131  27  90  97\n",
      "  77 123 100 112  82 194  26 184 130 197 104  79 165 188  92  95 177  68\n",
      " 184  32 127 184  72 154 187 166  50 112 157 104 110  53 127  79 171  21\n",
      " 154 152  77 127  84  18  45 142  87 138   9  44  32  31 156 179 160 173\n",
      " 171 102 100 144  45  72  33  43 107 166 154  46 186  90  94  92  40  14\n",
      " 124  92  26  81 156 162  73 149 189  61 117  87 171 115 128  41  94  93\n",
      " 122 193   3  84 158 107  91 166  19 187 162  92 156  71  92 168 165  54\n",
      " 161 166   5 177 147  86  17 109 142 173 165  94  92 191 165  92  72  15\n",
      "  81 166 186 194  25 149 145  30  43 163  73  54  97 113  33  93  56 187\n",
      " 182  45 184  22  80 126 188  43  36  92  36 172 143 127  23  56 172  93\n",
      "  82  94 134  47  73 169 196 171 196  91  18  33 115 161  45 166 196  26\n",
      "  86   9 180  82  45  23  92 171  78 165 126 111  32  68 195  19 154 181\n",
      "  48  52   2  39  82 147 186  94 191 152 185 154 101   2  13 131  63 116\n",
      "  28  53  96  81  46 119  53 120 115  25  84  30  34 183  32 111  22 185\n",
      "  61 106 106  12  96  90 158  97 163 147 175  22 181 106 179  12  99  77\n",
      "  41  96 106 169  46 125  72  97  51 153 152  36 192 156   0  76  97 118\n",
      " 123 133 192 181  52 174 184 176  31  60 152  74  17 142 156  49 196 112\n",
      "  93 122 147 129  28 111 120  57   3 194 181  52  81 105  66  63  95 110\n",
      "  63  52  81  51 102  97 146  78 134 114 153  41  56  52 190 146  99  44\n",
      "  56 169 130  35 135 172 105 139  56 166 155 181 190  79  51 115 116  44\n",
      " 104  86 179  89  17 114  65 161 127 115  38  22 161  47 154  71 107  87\n",
      "  86  60  82 135 193  51  65   4  81 158 191  59  80  52  27 181  63  78\n",
      " 101  36  52 116  63  85 185 112 173 157 133  86 152 129  63 194 169  27\n",
      "  84 191  25 195  61   7  83  95  83 197 165  88  38 195  21  95  75  25\n",
      "  54 194 102 161 148 161 135  72  61 191  56 170  46 193 101 132 128  92\n",
      " 136 154  88  18  19  76  27  97 121  99   9  95 176  97  42 139  71  40\n",
      " 152  74  17 110 196 147 191  13 153  88  34 169  49 153  65 127 162 175\n",
      " 134 103 105  43 130  12 173  16 147   4  10  30  29 119  88 103 149 167\n",
      " 114  98 169   9  73 187  21  22 195   0  45  13  42 140 161 172  90  40\n",
      " 149 114 168 168 169  86 145  73 198  95 137 100 169 105 163  95 135 111\n",
      "  59 173  14 142 125 138  99  36  14  43 125 120 183 107 105 110 154 193\n",
      "  31 148 164  38 191 101  27 122  87  61  90   3 122  56 165 194 100  22\n",
      " 160   2 156  12 164 187 121  64 184 193 133  87 150 155  81 198  81  96\n",
      " 163 175  36 160 136 112 181  64 193  50 120 193 180   0  94   6  11  17\n",
      "  91 163 106 109 187 130  32 173 145 192 102 150 175  27  85 199 138  47\n",
      "  15  72  99 116  91  51 177 101  23  27 170 195  32  90 163 160  98 102\n",
      "  97 100  81  85  69 110 186  45  14  91 169  89 176 124  35   1 128  57\n",
      " 164 139  30  31   7  82  66 183 115 139 162 123 174 182 121 174 159 113\n",
      " 103 187 118  64 127 154  99  46 190  59  84 138 171  49 141  57 118 126\n",
      "  91  40 194  16 107  95 191  40 109 129 154   7 174 199 178 153   4 114\n",
      " 159 123 175  37 127 123  36  28 196 156 105 118 111 197  25  26 124 161\n",
      "  71  49 127 196 115  75  31 103 160 127 185 100 104 107 167 129  37  51\n",
      "  16 105 171 154  81 124   6 180 138  99  27 103  31  19  18  60  74 130\n",
      "   9 127  22 196  27  50 175  70  14 189 130 191   9 123  81  99  71  14\n",
      " 125  37 136  22 145 151  17 110 106  13   0 101 124 135  71 117 197  79\n",
      "  48 164  86 108 169 158  84  86  93 117   9  31 110 178 178  76 109  51\n",
      " 106 110  41 193 146  57 100 164  47  95 198  85 173  25  21  59 136 114\n",
      "  21  60  90 122   0  79 103 179  82   7 100  99  86  53 108  95 150 129\n",
      " 109 188 100  31 139   0 123 118 170  48 129  57  74  11 153 192  92 155\n",
      " 118  29 152 137  95  23  19   4  99 161]\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "predictions = svm.predict(x_val)\n",
    "\n",
    "print(len(x_val))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果写入csv\n",
    "import pandas as pd\n",
    "\n",
    "submission = pd.read_csv('data/submission.csv', encoding='utf8')\n",
    "submission['预测结果'] = predictions\n",
    "submission.to_csv('data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
