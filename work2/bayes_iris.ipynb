{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先验概率\n",
    "def calculate_prior(y):\n",
    "    classes, cnt = np.unique(y, return_counts=True)\n",
    "    prior = cnt / y.shape[0]\n",
    "    return classes, prior\n",
    "\n",
    "# 每个类别下特征的均值和标准差\n",
    "def calculate_statistics(x,y):\n",
    "    classes = np.unique(y)\n",
    "    mean = np.zeros((len(classes), x.shape[1]), dtype=np.float64)\n",
    "    std = np.zeros((len(classes), x.shape[1]), dtype=np.float64)\n",
    "    \n",
    "    for idx, cls in enumerate(classes):\n",
    "        x_cls = x[y==cls]\n",
    "        mean[idx, : ] = x_cls.mean(axis=0)\n",
    "        std[idx, : ] = x_cls.std(axis=0)\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "# 每个类别下的特征似然\n",
    "def calculate_likelihood(mean, std, x):\n",
    "    e = np.exp(-((x - mean) ** 2 / (2 * std**2)))\n",
    "    likelihood = (1 / (np.sqrt(2 * np.pi) * std)) * e\n",
    "    return likelihood\n",
    "\n",
    "# 预测（取对处理）\n",
    "def predict(X, classes, prior, mean, std):\n",
    "    ret = []\n",
    "    for x in X:\n",
    "        pos = np.log(prior)\n",
    "        for idx, cls in enumerate(classes):\n",
    "            likelihood = calculate_likelihood(mean[idx], std[idx], x)\n",
    "            pos[idx] += np.sum(np.log(likelihood))\n",
    "        ret.append(classes[np.argmax(pos)])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "classes, prior = calculate_prior(y_trn)\n",
    "mean, std = calculate_statistics(x_trn, y_trn)\n",
    "\n",
    "# predict \n",
    "val_pd = pd.read_csv(\"iris_test.csv\", header=0)\n",
    "data_name = [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]\n",
    "x_val = val_pd[data_name].values.tolist()\n",
    "# print(x_val[0])\n",
    "y_pred = predict(x_val, classes, prior, mean, std)\n",
    "acc = np.mean(y_pred == y_val)\n",
    "print(f\"The accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = val_pd['sepal length (cm)']\n",
    "data_b = val_pd['sepal width (cm)']\n",
    "data_c = val_pd['petal length (cm)']\n",
    "data_d = val_pd['petal width (cm)']\n",
    "\n",
    "result = list(iris.target_names[y] for y in y_pred)\n",
    "res = pd.DataFrame({'sepal length (cm)':data_a, 'sepal width (cm)':data_b, 'petal length (cm)':data_c, 'petal width (cm)':data_d, 'species':result})\n",
    "res.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
