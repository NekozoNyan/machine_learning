{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集\n",
    "train_val_data = pd.read_csv('作业四/╫≈╥╡╦─/train.csv')\n",
    "\n",
    "# 加载测试数据集\n",
    "test_data = pd.read_csv('作业四/╫≈╥╡╦─/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 380 entries, 0 to 379\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  380 non-null    int64  \n",
      " 1   Pclass       380 non-null    int64  \n",
      " 2   Name         380 non-null    object \n",
      " 3   Sex          380 non-null    object \n",
      " 4   Age          302 non-null    float64\n",
      " 5   SibSp        380 non-null    int64  \n",
      " 6   Parch        380 non-null    int64  \n",
      " 7   Ticket       80 non-null     object \n",
      " 8   Fare         379 non-null    float64\n",
      " 9   Cabin        80 non-null     object \n",
      " 10  Embarked     350 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 查看训练集基本信息\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# 查看测试集基本信息\n",
    "train_val_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中具有缺失值的特征且其缺失值数量\n",
      "Age         177\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "测试集中具有缺失值的特征且其缺失值数量\n",
      "Age          78\n",
      "Ticket      300\n",
      "Fare          1\n",
      "Cabin       300\n",
      "Embarked     30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 识别具有NaN值的列\n",
    "train_val_nan_counts = train_val_data.isna().sum()\n",
    "train_val_columns_with_nan = train_val_nan_counts[train_val_nan_counts > 0]\n",
    "print('训练集中具有缺失值的特征且其缺失值数量')\n",
    "print(train_val_columns_with_nan)\n",
    "\n",
    "test_nan_counts = test_data.isna().sum()\n",
    "test_columns_with_nan = test_nan_counts[test_nan_counts > 0]\n",
    "print('测试集中具有缺失值的特征且其缺失值数量')\n",
    "print(test_columns_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 填充训练集中缺失值\n",
    "train_val_data.fillna({'Age': train_val_data['Age'].mean()}, inplace=True)\n",
    "train_val_data.fillna({'Embarked': train_val_data['Embarked'].mode()[0]}, inplace=True)\n",
    "\n",
    "# 填充测试集中缺失值\n",
    "# 用训练集的值填补缺失\n",
    "test_data.fillna({'Age' : train_val_data['Age'].mean()}, inplace=True)\n",
    "test_data.fillna({'Embarked' : train_val_data['Embarked'].mode()[0]}, inplace=True)  # 用训练集的众数填补缺失的登船港口\n",
    "test_data.fillna({'Fare': train_val_data['Fare'].mean()}, inplace=True)  # 用训练集的平均值填补缺失的票价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理分类特征\n",
    "label_encoder = LabelEncoder()\n",
    "train_val_data['Sex'] = label_encoder.fit_transform(train_val_data['Sex'])\n",
    "train_val_data['Embarked'] = label_encoder.fit_transform(train_val_data['Embarked'])\n",
    "\n",
    "test_data['Sex'] = label_encoder.fit_transform(test_data['Sex'])\n",
    "test_data['Embarked'] = label_encoder.fit_transform(test_data['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征选择\n",
    "# passangerId, Name, Ticket都对乘客是否生还没关系，而Cabin因为太多缺失值，所以也不作为训练特征\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X_train_val = train_val_data[features]\n",
    "y_train_val = train_val_data['Survived']\n",
    "\n",
    "X_test = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集的测试集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义计算熵的函数\n",
    "def entropy(y):\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)  # 获取标签中的唯一类及其计数\n",
    "    probabilities = counts / counts.sum()  # 计算每个类的概率\n",
    "    return -np.sum(probabilities * np.log2(probabilities))  # 计算熵\n",
    "\n",
    "# 定义计算信息增益的函数\n",
    "def information_gain(y, y_left, y_right):\n",
    "    p_left = len(y_left) / len(y)  # 左子集占整个集合的比例\n",
    "    p_right = len(y_right) / len(y)  # 右子集占整个集合的比例\n",
    "    return entropy(y) - p_left * entropy(y_left) - p_right * entropy(y_right)  # 计算信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义构建决策树的节点类\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature  # 用于分裂的特征索引\n",
    "        self.threshold = threshold  # 分裂的阈值\n",
    "        self.left = left  # 左子节点\n",
    "        self.right = right  # 右子节点\n",
    "        self.value = value  # 叶子节点的值\n",
    "\n",
    "# 定义构建决策树的类\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth  # 最大深度\n",
    "        self.root = None  # 根节点\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._grow_tree(X, y)  # 构建决策树\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape  # 样本数量和特征数量\n",
    "        # 如果样本数量少于等于1，或标签唯一，或达到最大深度，则创建叶子节点\n",
    "        if num_samples <= 1 or len(np.unique(y)) == 1 or (self.max_depth and depth >= self.max_depth):\n",
    "            leaf_value = self._most_common_label(y)  # 叶子节点的值为数据集中最常见的标签\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        best_feature, best_threshold = self._best_split(X, y)  # 寻找最佳分裂\n",
    "        if best_feature is None:  # 如果找不到最佳分裂，则创建叶子节点\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        left_indices = X[:, best_feature] < best_threshold  # 左子集的索引\n",
    "        right_indices = X[:, best_feature] >= best_threshold  # 右子集的索引\n",
    "        left_child = self._grow_tree(X[left_indices], y[left_indices], depth + 1)  # 构建左子树\n",
    "        right_child = self._grow_tree(X[right_indices], y[right_indices], depth + 1)  # 构建右子树\n",
    "        return Node(best_feature, best_threshold, left_child, right_child)  # 返回当前节点\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -1  # 初始化最佳增益\n",
    "        split_index, split_threshold = None, None  # 初始化最佳分裂点\n",
    "        for feature_index in range(X.shape[1]):  # 遍历每个特征\n",
    "            thresholds = np.unique(X[:, feature_index])  # 获取特征的唯一值\n",
    "            for threshold in thresholds:  # 遍历每个唯一值\n",
    "                left_indices = X[:, feature_index] < threshold  # 左子集的索引\n",
    "                right_indices = X[:, feature_index] >= threshold  # 右子集的索引\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:  # 如果子集为空，则跳过\n",
    "                    continue\n",
    "                gain = information_gain(y, y[left_indices], y[right_indices])  # 计算信息增益\n",
    "                if gain > best_gain:  # 如果增益大于当前最佳增益，则更新最佳分裂点\n",
    "                    best_gain = gain\n",
    "                    split_index = feature_index\n",
    "                    split_threshold = threshold\n",
    "        return split_index, split_threshold  # 返回最佳分裂点\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return np.bincount(y).argmax()  # 返回数据集中最常见的标签\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs) for inputs in X])  # 对每个输入样本进行预测\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.root  # 从根节点开始\n",
    "        while node.value is None:  # 如果不是叶子节点\n",
    "            if inputs[node.feature] < node.threshold:  # 根据特征值和阈值判断走向左子树还是右子树\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.value  # 返回叶子节点的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练自定义决策树模型\n",
    "tree = DecisionTree(max_depth=10)  # 设置最大深度为10\n",
    "tree.fit(X_train.values, y_train.values)  # 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "y_pred = tree.predict(X_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8044692737430168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84       105\n",
      "           1       0.82      0.68      0.74        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.81      0.79      0.79       179\n",
      "weighted avg       0.81      0.80      0.80       179\n",
      "\n",
      "confusion_matrix:\n",
      "[[94 11]\n",
      " [24 50]]\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "accuracy = accuracy_score(y_val.values, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print('confusion_matrix:')\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "y_test_pred = tree.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载submission文件\n",
    "submission = pd.read_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果填充到submission.csv\n",
    "submission['Survived'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存预测结果到submission.csv\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
