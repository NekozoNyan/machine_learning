{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "\n",
    "# 处理缺失值\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "# data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "\n",
    "# 转换分类特征\n",
    "label_encoder = LabelEncoder()\n",
    "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
    "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
    "\n",
    "x = data[features].values.tolist()\n",
    "y = data[target].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算熵\n",
    "def entropy(data):\n",
    "    label_counts = Counter(data)\n",
    "    total_count = len(data)\n",
    "    return -sum(\n",
    "        (count / total_count) * math.log2(count / total_count)\n",
    "        for count in label_counts.values()\n",
    "    )\n",
    "\n",
    "\n",
    "# 按特征划分数据集\n",
    "def split_dataset(data, labels, axis, value):\n",
    "    ret_dataset = []\n",
    "    ret_labels = []\n",
    "    for row, label in zip(data, labels):\n",
    "        if row[axis] == value:\n",
    "            reduced_row = row[:axis] + row[axis + 1 :]\n",
    "            ret_dataset.append(reduced_row)\n",
    "            ret_labels.append(label)\n",
    "    return ret_dataset, ret_labels\n",
    "\n",
    "\n",
    "# 选择最佳划分特征\n",
    "def choose_best_feature_to_split(data, labels):\n",
    "    num_features = len(data[0])\n",
    "    base_entropy = entropy(labels)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = -1\n",
    "    for i in range(num_features):\n",
    "        unique_vals = set(row[i] for row in data)\n",
    "        new_entropy = 0.0\n",
    "        for value in unique_vals:\n",
    "            subset, subset_labels = split_dataset(data, labels, i, value)\n",
    "            prob = len(subset) / float(len(data))\n",
    "            new_entropy += prob * entropy(subset_labels)\n",
    "        info_gain = base_entropy - new_entropy\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature, best_info_gain\n",
    "\n",
    "\n",
    "# 多数表决\n",
    "def majority_cnt(class_list):\n",
    "    return Counter(class_list).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "# 递归创建决策树，包含预剪枝\n",
    "def create_tree(\n",
    "    data, labels, feature_names, max_depth=None, min_info_gain=0.01, depth=0\n",
    "):\n",
    "    class_list = labels\n",
    "    if class_list.count(class_list[0]) == len(class_list):\n",
    "        return class_list[0]\n",
    "    if len(data[0]) == 0:\n",
    "        return majority_cnt(class_list)\n",
    "    if max_depth is not None and depth >= max_depth:\n",
    "        return majority_cnt(class_list)\n",
    "    best_feature, best_info_gain = choose_best_feature_to_split(data, labels)\n",
    "    if best_info_gain < min_info_gain:\n",
    "        return majority_cnt(class_list)\n",
    "    best_feature_name = feature_names[best_feature]\n",
    "    tree = {best_feature_name: {}}\n",
    "    unique_vals = set(row[best_feature] for row in data)\n",
    "    for value in unique_vals:\n",
    "        sub_feature_names = (\n",
    "            feature_names[:best_feature] + feature_names[best_feature + 1 :]\n",
    "        )\n",
    "        subset, subset_labels = split_dataset(data, labels, best_feature, value)\n",
    "        tree[best_feature_name][value] = create_tree(\n",
    "            subset,\n",
    "            subset_labels,\n",
    "            sub_feature_names,\n",
    "            max_depth,\n",
    "            min_info_gain,\n",
    "            depth + 1,\n",
    "        )\n",
    "    return tree\n",
    "\n",
    "\n",
    "# 预测函数\n",
    "def predict(tree, feature_names, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    root = next(iter(tree))\n",
    "    child = tree[root]\n",
    "    feature_index = feature_names.index(root)\n",
    "    feature_value = sample[feature_index]\n",
    "    \n",
    "    if feature_value in child:\n",
    "        return predict(child[feature_value], feature_names, sample)\n",
    "    else:\n",
    "        subtree_values = [v for v in child.values() if not isinstance(v, dict)]\n",
    "        \n",
    "        if subtree_values:\n",
    "            return majority_cnt(subtree_values)\n",
    "        else:\n",
    "            return majority_cnt(child)\n",
    "\n",
    "\n",
    "# 后剪枝函数\n",
    "def post_prune(tree, validation_data, validation_labels, feature_names):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    root = next(iter(tree))\n",
    "    subtrees = tree[root]\n",
    "    feature_index = feature_names.index(root)\n",
    "    for key in subtrees:\n",
    "        if isinstance(subtrees[key], dict):\n",
    "            subtrees[key] = post_prune(\n",
    "                subtrees[key], validation_data, validation_labels, feature_names\n",
    "            )\n",
    "\n",
    "    # 计算未剪枝的误差\n",
    "    unpruned_error = sum(\n",
    "        predict(tree, feature_names, sample) != label\n",
    "        for sample, label in zip(validation_data, validation_labels)\n",
    "    )\n",
    "\n",
    "    # 计算剪枝后的误差\n",
    "    majority_class = majority_cnt(validation_labels)\n",
    "    pruned_error = sum(majority_class != label for label in validation_labels)\n",
    "\n",
    "    # 如果剪枝后的误差更小，则进行剪枝\n",
    "    if pruned_error <= unpruned_error:\n",
    "        return majority_class\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fare': {0.0: 0, 512.3292: 1, 4.0125: 0, 6.975: 0, 7.925: 0, 8.05: 0, 7.25: {'Sex': {0.0: 1, 1.0: 0}}, 8.4583: 0, 11.1333: 1, 7.8542: 0, 13.0: 0, 7.225: 0, 8.0292: 1, 16.7: 1, 16.0: 1, 18.0: 0, 11.2417: 1, 15.5: 0, 21.075: 0, 21.0: 0, 21.6792: 0, 17.8: 0, 20.575: 0, 26.55: 0, 26.0: 0, 27.7208: {'Sex': {0.0: 1, 1.0: 0}}, 29.125: 0, 30.0708: {'Sex': {0.0: 1, 1.0: 0}}, 31.275: 0, 31.3875: 0, 27.75: {'Sex': {0.0: 1, 1.0: 0}}, 27.9: 0, 35.5: 0, 7.75: 0, 29.0: 1, 34.375: 0, 39.6875: 0, 34.6542: 0, 41.5792: {'Sex': {0.0: 1, 1.0: 0}}, 7.1417: 1, 36.75: 0, 7.7958: {'Age': {18.0: 0, 21.0: 1, 22.0: 0, 24.0: 0, 27.0: 1}}, 7.3125: 0, 46.9: 0, 9.0: 0, 9.5: 0, 47.1: 0, 50.0: 0, 51.8625: {'Sex': {0.0: 1, 1.0: 0}}, 10.5: 0, 53.1: {'Sex': {0.0: 1, 1.0: 0}}, 52.0: {'Sex': {0.0: 1, 1.0: 0}}, 55.0: 1, 56.4958: 0, 11.5: 0, 52.5542: 1, 56.9292: 1, 57.9792: 1, 61.9792: 0, 61.175: 0, 63.3583: 1, 61.3792: 0, 12.875: 0, 66.6: {'Sex': {0.0: 1, 1.0: 0}}, 13.5: {'Sex': {0.0: 1, 1.0: 0}}, 12.0: 1, 69.55: 0, 69.3: 1, 71.2833: 1, 14.4542: 0, 73.5: 0, 14.5: {'Pclass': {2.0: 1, 3.0: 0}}, 14.0: 0, 76.7292: 1, 77.2875: 0, 15.0458: 0, 79.2: 0, 80.0: 1, 16.1: 0, 82.1708: {'Sex': {0.0: 1, 1.0: 0}}, 83.475: {'Sex': {0.0: 1, 1.0: 0}}, 15.75: 1, 76.2917: 1, 86.5: 1, 79.65: {'Sex': {0.0: 1, 1.0: 0}}, 83.1583: 1, 81.8583: 1, 90.0: 0, 18.7875: 1, 91.0792: 1, 18.75: 1, 89.1042: 1, 93.5: 1, 19.5: 1, 19.2583: 1, 7.2292: {'Sex': {0.0: 1, 1.0: 0}}, 20.525: 0, 20.2125: 0, 20.25: 1, 7.7292: 0, 106.425: {'Sex': {0.0: 1, 1.0: 0}}, 108.9: {'Sex': {0.0: 1, 1.0: 0}}, 110.8833: 0, 22.3583: 1, 22.025: 1, 113.275: {'Sex': {0.0: 1, 1.0: 0}}, 22.525: 0, 23.0: 1, 23.25: 1, 120.0: 1, 24.15: 0, 24.0: 0, 25.5875: 0, 26.25: {'Sex': {0.0: 1, 1.0: 0}}, 26.2875: 1, 133.65: 1, 134.5: 1, 135.6333: {'Sex': {0.0: 1, 1.0: 0}}, 27.0: {'Sex': {0.0: 1, 1.0: 0}}, 28.7125: 0, 28.5: 0, 146.5208: 1, 30.6958: 0, 151.55: 0, 153.4625: {'Sex': {0.0: 1, 1.0: 0}}, 30.5: 0, 30.0: 1, 6.75: 0, 31.0: 0, 32.5: 1, 32.3208: 0, 7.65: {'Sex': {0.0: 1, 1.0: 0}}, 7.775: 0, 164.8667: 1, 33.5: 0, 33.0: 1, 8.7125: 0, 10.1708: 0, 34.0208: 0, 9.8375: 0, 9.5875: 0, 35.0: 0, 10.4625: 0, 7.125: 0, 7.875: 0, 12.525: 0, 12.275: 0, 12.65: 1, 38.5: 0, 13.7917: 1, 13.4167: 1, 39.0: 0, 39.6: 1, 14.4: 0, 40.125: 0, 15.9: 1, 211.5: 0, 42.4: 0, 211.3375: 1, 221.7792: 0, 6.2375: 0, 17.4: 1, 227.525: {'Sex': {0.0: 1, 1.0: 0}}, 7.8792: 1, 7.8: 0, 7.05: 0, 7.55: 0, 7.6292: 0, 247.5208: {'Sex': {0.0: 1, 1.0: 0}}, 49.5042: {'Sex': {0.0: 1, 1.0: 0}}, 49.5: 1, 51.4792: 1, 262.375: 1, 263.0: {'Sex': {0.0: 1, 1.0: 0}}, 55.4417: 1, 55.9: {'Sex': {0.0: 1, 1.0: 0}}, 57.0: 1, 8.1583: 0, 8.6542: 0, 8.4042: 0, 8.1125: 1, 59.4: 1, 9.825: 0, 9.2167: 0, 8.4333: 0, 9.8417: 1, 8.1375: 0, 13.8625: 1, 65.0: 1, 15.2458: 0, 15.05: 0, 15.55: 0, 6.4958: 0, 19.9667: 0, 7.4958: 0, 71.0: 1, 75.25: 1, 15.0: 0, 25.925: 0, 25.4667: 0, 26.2833: 1, 77.9583: 1, 26.3875: 1, 78.85: 1, 78.2667: 1, 29.7: 0, 7.8292: {'Sex': {0.0: 1, 1.0: 0}}, 7.7875: 1, 7.725: 0, 7.0542: 0, 7.7417: 0, 8.6625: 0, 8.85: 0, 9.475: 0, 9.35: 0, 9.225: 0, 6.8583: 0, 12.475: 1, 12.35: {'Sex': {0.0: 1, 1.0: 0}}, 12.2875: 1, 14.4583: 0, 15.85: {'Sex': {0.0: 1, 1.0: 0}}, 15.7417: 1, 15.1: 0, 7.7333: {'Sex': {0.0: 1, 1.0: 0}}, 7.0458: 0, 7.8958: 0, 7.5208: 0}}\n"
     ]
    }
   ],
   "source": [
    "# 创建决策树并预剪枝\n",
    "feature_names = features[:]\n",
    "trn_data = x[: int(0.8 * len(x))]\n",
    "trn_labels = y[: int(0.8 * len(y))]\n",
    "val_data = x[int(0.8 * len(x)) :]\n",
    "val_labels = y[int(0.8 * len(y)) :]\n",
    "\n",
    "decision_tree = create_tree(\n",
    "    trn_data,\n",
    "    trn_labels,\n",
    "    feature_names,\n",
    "    max_depth=5,\n",
    "    min_info_gain=0.01,\n",
    ")\n",
    "\n",
    "# 后剪枝\n",
    "decision_tree = post_prune(\n",
    "    decision_tree, val_data, val_labels, feature_names\n",
    ")\n",
    "\n",
    "print(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1]\n",
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "def evaluate(tree, feature_names, X, y):\n",
    "    predictions = [predict(tree, feature_names, sample) for sample in X]\n",
    "    accuracy = sum(1 for true, pred in zip(y, predictions) if true == pred) / len(y)\n",
    "    return predictions, accuracy\n",
    "\n",
    "# 评估剪枝后的决策树\n",
    "_, accuracy = evaluate(decision_tree, feature_names, val_data, val_labels)\n",
    "print(_[:5])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0, 1.0, 22.0, 1.0, 0.0, 7.25, 2.0], [1.0, 0.0, 38.0, 1.0, 0.0, 71.2833, 0.0], [3.0, 0.0, 26.0, 0.0, 0.0, 7.925, 2.0], [1.0, 0.0, 35.0, 1.0, 0.0, 53.1, 2.0], [3.0, 1.0, 35.0, 0.0, 0.0, 8.05, 2.0]]\n",
      "[[1.0, 1.0, 37.0, 1.0, 1.0, 83.80399906, 1.0], [1.0, 1.0, 47.0, 0.0, 0.0, 43.38316529, 3.0], [3.0, 0.0, 21.0, 1.0, 1.0, 13.18401399, 3.0], [3.0, 0.0, 30.0, 0.0, 0.0, 8.694805595, 0.0], [3.0, 0.0, 10.0, 5.0, 2.0, 47.73594325, 0.0]]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/nekozo/newSpace/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# 读取测试数据\n",
    "test_pd = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# 处理缺失值\n",
    "test_pd[\"Age\"].fillna(data[\"Age\"].mean(), inplace=True)\n",
    "test_pd[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0], inplace=True)\n",
    "test_pd[\"Fare\"].fillna(data[\"Fare\"].mean(), inplace=True)\n",
    "\n",
    "# 转换分类特征\n",
    "test_pd[\"Sex\"] = label_encoder.fit_transform(test_pd[\"Sex\"])\n",
    "test_pd[\"Embarked\"] = label_encoder.fit_transform(test_pd[\"Embarked\"].astype(str))\n",
    "\n",
    "# 准备测试数据\n",
    "val_x = test_pd[features].values.tolist()\n",
    "print(trn_data[:5])\n",
    "print(val_x[:5])\n",
    "\n",
    "\n",
    "# 预测函数\n",
    "def predict_survived(val_x, decision_tree, feature_names):\n",
    "    return [predict(decision_tree, feature_names, sample) for sample in val_x]\n",
    "\n",
    "# 进行预测\n",
    "predictions = predict_survived(val_x, decision_tree, feature_names)\n",
    "print(predictions)\n",
    "\n",
    "# 将预测结果保存到submission.csv中\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "submission[\"Survived\"] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
